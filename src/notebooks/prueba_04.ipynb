{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a06c08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender  Age  Occupation  Sleep Duration  Quality of Sleep  \\\n",
      "0       1   27           9             6.1                 6   \n",
      "1       1   27           9             6.1                 6   \n",
      "2       1   27           9             6.1                 6   \n",
      "3       1   27           9             6.1                 6   \n",
      "4       1   27           9             6.1                 6   \n",
      "\n",
      "   Physical Activity Level  Stress Level  BMI Category  Blood Pressure  \\\n",
      "0                       42             6             3              11   \n",
      "1                       42             6             3              11   \n",
      "2                       42             6             3              11   \n",
      "3                       42             6             3              11   \n",
      "4                       42             6             3              11   \n",
      "\n",
      "   Heart Rate  Daily Steps  Diagnosis_Confirmed Sleep_disorder  \n",
      "0          77         4200                    1              1  \n",
      "1          77         4200                    1              3  \n",
      "2          77         4200                    1              0  \n",
      "3          77         4200                    1              3  \n",
      "4          77         4200                    1              0  \n",
      "Sleep_disorder\n",
      "0    0.335550\n",
      "3    0.218085\n",
      "5    0.217199\n",
      "4    0.094415\n",
      "1    0.082890\n",
      "2    0.051862\n",
      "Name: proportion, dtype: float64\n",
      "=== RandomForest Baseline ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nsara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nsara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nsara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.72      0.65       152\n",
      "           1       0.19      0.11      0.14        37\n",
      "           2       0.00      0.00      0.00        23\n",
      "           3       0.49      0.59      0.53        99\n",
      "           4       0.10      0.05      0.06        43\n",
      "           5       0.88      0.94      0.91        98\n",
      "\n",
      "    accuracy                           0.59       452\n",
      "   macro avg       0.37      0.40      0.38       452\n",
      "weighted avg       0.52      0.59      0.55       452\n",
      "\n",
      "=== RF con class_weight='balanced' ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.46      0.61       152\n",
      "           1       0.22      0.41      0.29        37\n",
      "           2       0.12      0.35      0.18        23\n",
      "           3       0.48      0.43      0.46        99\n",
      "           4       0.24      0.28      0.26        43\n",
      "           5       0.91      0.93      0.92        98\n",
      "\n",
      "    accuracy                           0.53       452\n",
      "   macro avg       0.48      0.48      0.45       452\n",
      "weighted avg       0.65      0.53      0.56       452\n",
      "\n",
      "=== RF con SMOTE ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.47      0.59       152\n",
      "           1       0.27      0.41      0.33        37\n",
      "           2       0.12      0.26      0.16        23\n",
      "           3       0.44      0.48      0.46        99\n",
      "           4       0.22      0.23      0.23        43\n",
      "           5       0.91      0.93      0.92        98\n",
      "\n",
      "    accuracy                           0.54       452\n",
      "   macro avg       0.46      0.46      0.45       452\n",
      "weighted avg       0.61      0.54      0.56       452\n",
      "\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    }
   ],
   "source": [
    "# 1. Carga de librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelos y utilidades\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Preprocesado\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# Para pipelines que contengan SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 2. Carga y EDA rápida\n",
    "df = pd.read_csv('../data/combined_sleep_dataset.csv')\n",
    "\n",
    "# Convertir la etiqueta a categórica\n",
    "df['Sleep_disorder'] = df['Sleep_disorder'].astype('category')\n",
    "\n",
    "# Ver primer vistazo\n",
    "print(df.head())\n",
    "print(df['Sleep_disorder'].value_counts(normalize=True))  # desequilibrio de clases\n",
    "\n",
    "# 3. Definir X e y\n",
    "X = df.drop(columns=['Sleep_disorder', 'Diagnosis_Confirmed'])\n",
    "y = df['Sleep_disorder']\n",
    "\n",
    "# 4. División entrenamiento / prueba (estratificada)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 5. Identificar columnas numéricas y categóricas\n",
    "num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "# 6. Definir preprocesador (escalado + one-hot)\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "# --- 7. MODELO BASELINE: RandomForest sin balance ---\n",
    "rf_baseline = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "y_pred = rf_baseline.predict(X_test)\n",
    "print(\"=== RandomForest Baseline ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=y.cat.categories.astype(str)))\n",
    "\n",
    "# --- 8. MODELO con class_weight='balanced' en RF ---\n",
    "rf_balanced = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "rf_balanced.fit(X_train, y_train)\n",
    "y_pred = rf_balanced.predict(X_test)\n",
    "print(\"=== RF con class_weight='balanced' ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=y.cat.categories.astype(str)))\n",
    "\n",
    "# --- 9. MODELO con SMOTE + RF ---\n",
    "rf_smote = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('smote',   SMOTE(random_state=42)),\n",
    "    ('clf',     RandomForestClassifier(random_state=42))\n",
    "])\n",
    "rf_smote.fit(X_train, y_train)\n",
    "y_pred = rf_smote.predict(X_test)\n",
    "print(\"=== RF con SMOTE ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=y.cat.categories.astype(str)))\n",
    "\n",
    "# --- 10. GRID SEARCH LIGHTGBM (optimiza f1_macro) ---\n",
    "pipeline_lgb = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('smote',   SMOTE(random_state=42)),\n",
    "    ('clf',     LGBMClassifier(random_state=42, class_weight='balanced', n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators':  [100, 200],\n",
    "    'clf__max_depth':     [5, 7, 9],\n",
    "    'clf__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'clf__subsample':     [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_lgb = GridSearchCV(\n",
    "    pipeline_lgb,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1_macro',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_lgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros LightGBM:\", grid_lgb.best_params_)\n",
    "y_pred = grid_lgb.predict(X_test)\n",
    "print(\"=== LightGBM optimizado (f1_macro) ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=y.cat.categories.astype(str)))\n",
    "\n",
    "# --- 11. ENSAMBLE con VotingClassifier ---\n",
    "#    usaremos 3 bases con distinto tratamiento para diversificar\n",
    "pipe_rf = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('smote',   SMOTE(random_state=42)),\n",
    "    ('rf',      RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "pipe_xgb = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    # sin SMOTE para XGB\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss',\n",
    "                          learning_rate=0.05, max_depth=7, n_estimators=100,\n",
    "                          random_state=42))\n",
    "])\n",
    "pipe_lgb = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('smote',   SMOTE(random_state=42)),\n",
    "    ('lgb',     LGBMClassifier(**grid_lgb.best_params_['clf'], random_state=42))\n",
    "])\n",
    "\n",
    "voting = VotingClassifier(\n",
    "    estimators=[('rf', pipe_rf), ('xgb', pipe_xgb), ('lgb', pipe_lgb)],\n",
    "    voting='soft',\n",
    "    weights=[1,1,2],   # damos doble peso al modelo LightGBM mejor optimizado\n",
    "    n_jobs=-1\n",
    ")\n",
    "voting.fit(X_train, y_train)\n",
    "y_pred = voting.predict(X_test)\n",
    "print(\"=== VotingClassifier (RF+XGB+LGBM) ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=y.cat.categories.astype(str)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
